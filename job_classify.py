# -*- coding: utf-8 -*-
"""job classify

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19QrIQhySJ0JBPkciZ4nglH_MeLJ7mHIt
"""

# Install necessary packages
!pip install requests beautifulsoup4 scikit-learn joblib

import requests
from bs4 import BeautifulSoup
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import joblib
import os
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# ----------- SCRAPER -----------
def scrape_karkidi():
    url = "https://www.karkidi.com/Job-search"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, "html.parser")

    job_listings = []

    # You must inspect actual HTML and update below selectors accordingly:
    job_cards = soup.find_all("div", class_="job-listing")  # Example class

    if not job_cards:
        # fallback if above fails
        job_cards = soup.find_all("div")

    for job_card in job_cards:
        title = job_card.find("h2") or job_card.find("a", class_="job-title")
        company = job_card.find("h3") or job_card.find("div", class_="company-name")
        link = job_card.find("a", href=True)
        skills = job_card.find("p", class_="skills") or job_card.find("div", class_="skills")
        date_posted = job_card.find("span", class_="date")

        if title and company and link and skills:
            job_listings.append({
                "title": title.get_text(strip=True),
                "company": company.get_text(strip=True),
                "skills": skills.get_text(strip=True),
                "date": date_posted.get_text(strip=True) if date_posted else "",
                "link": "https://www.karkidi.com" + link['href']
            })

    return pd.DataFrame(job_listings)

# ----------- CLUSTERING -----------
def cluster_jobs(jobs_df, n_clusters=5):
    vectorizer = TfidfVectorizer(stop_words='english')
    X = vectorizer.fit_transform(jobs_df['skills'].fillna(""))
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(X)
    jobs_df['cluster'] = clusters
    joblib.dump((kmeans, vectorizer), "/content/karkidi_model.pkl")
    return jobs_df

def classify_new_jobs(jobs_df):
    if os.path.exists("/content/karkidi_model.pkl"):
        kmeans, vectorizer = joblib.load("/content/karkidi_model.pkl")
        X_new = vectorizer.transform(jobs_df['skills'].fillna(""))
        jobs_df['cluster'] = kmeans.predict(X_new)
    else:
        jobs_df = cluster_jobs(jobs_df)
    return jobs_df

# ----------- DATA HANDLING -----------
def load_previous_jobs(filepath="/content/previous_jobs.pkl"):
    if os.path.exists(filepath):
        return pd.read_pickle(filepath)
    else:
        return pd.DataFrame(columns=['title', 'company', 'skills', 'date', 'link', 'cluster'])

def save_jobs(jobs_df, filepath="/content/previous_jobs.pkl"):
    jobs_df.to_pickle(filepath)

# ----------- EMAIL NOTIFICATIONS -----------
def send_email(to_email, subject, body, from_email, from_password, smtp_server="smtp.gmail.com", smtp_port=587):
    msg = MIMEMultipart()
    msg['From'] = from_email
    msg['To'] = to_email
    msg['Subject'] = subject

    msg.attach(MIMEText(body, 'plain'))

    try:
        server = smtplib.SMTP(smtp_server, smtp_port)
        server.starttls()
        server.login(from_email, from_password)
        server.send_message(msg)
        server.quit()
        print(f"Email sent to {to_email}")
    except Exception as e:
        print(f"Failed to send email to {to_email}: {e}")

def notify_users(new_jobs, user_prefs, email_config):
    for user_email, preferred_clusters in user_prefs.items():
        matches = new_jobs[new_jobs['cluster'].isin(preferred_clusters)]
        if not matches.empty:
            body_lines = [f"New job matches for you:\n"]
            for _, row in matches.iterrows():
                body_lines.append(f"- {row['title']} at {row['company']} ({row['link']})")
            body = "\n".join(body_lines)
            send_email(
                to_email=user_email,
                subject="New Job Alerts from Karkidi",
                body=body,
                from_email=email_config['email'],
                from_password=email_config['password'],
                smtp_server=email_config.get('smtp_server', "smtp.gmail.com"),
                smtp_port=email_config.get('smtp_port', 587)
            )
        else:
            print(f"No new matching jobs for {user_email}")

# ----------- MAIN MONITORING FUNCTION -----------
def monitor_karkidi(user_preferences, email_config):
    print("Scraping new jobs...")
    current_jobs = scrape_karkidi()

    if current_jobs.empty or 'skills' not in current_jobs.columns:
        print("No jobs found or 'skills' column missing. Check selectors.")
        return

    current_jobs = classify_new_jobs(current_jobs)
    prev_jobs = load_previous_jobs()

    new_jobs = current_jobs[~current_jobs['link'].isin(prev_jobs['link'])]
    print(f"Found {len(new_jobs)} new jobs.")

    if not new_jobs.empty:
        notify_users(new_jobs, user_preferences, email_config)
    else:
        print("No new jobs matching user preferences.")

    save_jobs(current_jobs)

# ----------- USER CONFIGURATION -----------
user_preferences = {
    "user1@example.com": [0, 2],  # Clusters user 1 wants
    "user2@example.com": [1],     # Clusters user 2 wants
}

email_config = {
    "email": "your_email@gmail.com",        # Your Gmail address
    "password": "your_app_password",        # Your Gmail App Password (not your normal password)
}

# ----------- RUN MONITOR -----------
monitor_karkidi(user_preferences, email_config)